{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427f9b6b-7292-4500-99b5-c1c603abe047",
   "metadata": {},
   "source": [
    "\n",
    "- liens qui ne sont pas des pdfs -> pointent vers pages ou autres pdfs (https://www.ahv-iv.ch/fr/M%C3%A9mentos/Prestations-de-lAI)\n",
    "\n",
    "- better table parsing with (careful with headers !!!)\n",
    "- envoyer structured_content à flash pour l'injection de liens\n",
    "- 2e passe avec flash pour traduire les descriptions d'images ou alt-text pas dans la bonne langue\n",
    "  \n",
    "### data augmentation\n",
    "- extract links and create KG triplets\n",
    "- hyq/declarative hyq\n",
    "- extract topic/subtopics/etc.\n",
    "- maybe do summary here? !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d693c0f-ffb7-4bb1-8d07-c5b219cd11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import pathlib\n",
    "from pydantic import BaseModel\n",
    "import glob\n",
    "import fitz  # PyMuPDF\n",
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470972d5-5f19-454f-899d-1144c982b194",
   "metadata": {},
   "source": [
    "# Env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d389bde3-b2df-421b-a043-2439eacbb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da531819-3b59-421b-8131-b6c89a4e9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"f\"\n",
    "PDF_PATH = os.path.join(\"../pdfs\", lang)\n",
    "OUTPUT_PATH = os.path.join(\"../parsed_pdfs\", lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d04aa-4af2-44cc-8e46-912de61eab7d",
   "metadata": {},
   "source": [
    "# VLM parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36824158-3f7c-40af-95e5-86614cdaafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/parse_pdf_to_text.txt\", \"r\") as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "class SectionContent(BaseModel):\n",
    "    page_number: List[int]\n",
    "    header: str\n",
    "    content: str\n",
    "\n",
    "class StructuredContent(BaseModel):\n",
    "    section_header: str\n",
    "    section_content: List[SectionContent]\n",
    "    \n",
    "class PageContent(BaseModel):\n",
    "    page_number: int\n",
    "    page_content: str\n",
    "\n",
    "class ParsedDocument(BaseModel):\n",
    "    content: List[PageContent]\n",
    "    structured_content: List[StructuredContent]\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d722a0d8-1336-4cba-988a-ddd1480feb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [f for f in os.listdir(PDF_PATH) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc84445-b1ac-441f-a36d-baee7b249b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [\"2_01_f.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1155a3-f4f0-4dc7-a931-d906a433057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 2_01_f.pdf\n"
     ]
    }
   ],
   "source": [
    "for fn in pdf_files:\n",
    "    print(f\"Processing: {fn}\")\n",
    "    \n",
    "    pdf_path = os.path.join(PDF_PATH, fn)\n",
    "    pdf_bytes = pathlib.Path(pdf_path).read_bytes()\n",
    "\n",
    "    # Create output filename using the same name as the PDF but with .txt extension\n",
    "    output_file = os.path.join(OUTPUT_PATH, fn.replace(\".pdf\", \".txt\"))\n",
    "\n",
    "    # VLM call\n",
    "    response = client.models.generate_content(\n",
    "      model=\"gemini-2.5-pro-exp-03-25\",\n",
    "      contents=[\n",
    "          types.Part.from_bytes(\n",
    "            data=pdf_bytes,\n",
    "            mime_type='application/pdf',\n",
    "          ),\n",
    "          prompt],\n",
    "      config={\n",
    "            'response_mime_type': 'application/json',\n",
    "            'response_schema': ParsedDocument,\n",
    "        }\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f09ca2-c814-47b2-a321-cf0219ce18f1",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9916b4e0-666d-404d-b300-e67c018f9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages_and_links_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    link_data = []\n",
    "    n_pages = 0\n",
    "    for page_n, page in enumerate(doc):\n",
    "        n_pages += 1\n",
    "        links = page.get_links()\n",
    "        for link in links:\n",
    "            if 'uri' in link:\n",
    "                rect = link['from']\n",
    "                text = page.get_textbox(rect).strip()\n",
    "                link_data.append((page_n+1, text, link['uri']))\n",
    "    return n_pages, link_data\n",
    "\n",
    "def replace_special_chars(text: str) -> str:\n",
    "    replacements = {\n",
    "        \"ß\": \"ss\",\n",
    "    }\n",
    "    for orig, repl in replacements.items():\n",
    "        text = text.replace(orig, repl)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9e1570-c8af-4451-beed-2e0684a1db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/link_injection.txt\", \"r\") as f:\n",
    "    prompt = f.read()\n",
    "    \n",
    "class MarkdownContentWithUrl(BaseModel):\n",
    "        current_page_markdown_content: str\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11666852-64c3-4084-881f-b61e409a5ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, '2.03 -', 'https://www.ahv-iv.ch/p/2.03.f'),\n",
       " (3,\n",
       "  'Cotisations des personnes sans activité lucrative à l’AVS, à l’AI et aux APG)',\n",
       "  'https://www.ahv-iv.ch/p/2.03.f'),\n",
       " (3,\n",
       "  '2.08 - Cotisations à l’assurance-chômage',\n",
       "  'https://www.ahv-iv.ch/p/2.08.f'),\n",
       " (5, '2', 'https://www.ahv-iv.ch/p/2.07.f'),\n",
       " (5,\n",
       "  '2.07 - Procédures de décompte simplifiées pour les employeurs)',\n",
       "  'https://www.ahv-iv.ch/p/2.07.f'),\n",
       " (8,\n",
       "  'e, si elles ne sont pas exceptées du salaire déterminant \\n2.05 - Rémunérations versées lors de la cessation des \\nvail) ;',\n",
       "  'https://www.ahv-iv.ch/p/2.05.f'),\n",
       " (8,\n",
       "  '(voir mémento 2.0\\nrapports de travail',\n",
       "  'https://www.ahv-iv.ch/p/2.05.f'),\n",
       " (8,\n",
       "  'de travail pour cause d’intempéries au sens de l’AC (voir\\n2.11 - Obligation de cotiser sur les indemnités en cas de\\nde l’horaire de travail ou d’intempéries) ;',\n",
       "  'https://www.ahv-iv.ch/p/2.11.f'),\n",
       " (8,\n",
       "  'mémento 2.11 - Obligation de cotiser sur les in\\nréduction de l’horaire de travail ou d’intempéries',\n",
       "  'https://www.ahv-iv.ch/p/2.11.f'),\n",
       " (11,\n",
       "  '3.08 – Nouveau calcul de la rente de vieillesse après l’âge de réfé\\xad',\n",
       "  'https://www.ahv-iv.ch/p/3.08.f'),\n",
       " (11, 'rence', 'https://www.ahv-iv.ch/p/3.08.f'),\n",
       " (11,\n",
       "  'Stabilisation de l’AVS [AVS 21] Qu’est-ce qui change)',\n",
       "  'https://www.ahv-iv.ch/p/31.f'),\n",
       " (14, '2.06 - Travail domestique)', 'https://www.ahv-iv.ch/p/2.06.f'),\n",
       " (17,\n",
       "  '6.09 - Allocations familiales dans l’agriculture',\n",
       "  'https://www.ahv-iv.ch/p/6.09.f'),\n",
       " (18, 'www.avs-ai.ch', 'https://www.ahv-iv.ch/fr/Contacts'),\n",
       " (18,\n",
       "  '',\n",
       "  'https://www.ahv-iv.ch/fr/Assurances-sociales/Assurance-vieillesse-et-survivants-AVS')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = os.path.join(PDF_PATH, fn)\n",
    "\n",
    "n_pages, links_to_inject = extract_pages_and_links_from_pdf(pdf_path)\n",
    "\n",
    "links_to_inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9ae4d18-6bd1-4c5d-a780-0a99196c70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by page_number (first element of tuple)\n",
    "links_to_inject.sort(key=itemgetter(0))\n",
    "\n",
    "# Group by page_number\n",
    "grouped_links = {\n",
    "    key: list(group)\n",
    "    for key, group in groupby(links_to_inject, key=itemgetter(0))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffab36-e6ab-4ee0-b32c-8e6f923e9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_number, links in grouped_links.items():\n",
    "\n",
    "    print(page_number)\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    current_page = next((p for p in response.parsed.content if p.page_number == page_number), None)\n",
    "    if not current_page: \n",
    "        break\n",
    "\n",
    "    current_page.page_content = replace_special_chars(current_page.page_content)\n",
    "    print(current_page.page_content)\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    links_to_inject = [(x[1], x[2]) for x in links]\n",
    "    print(links_to_inject)\n",
    "    print(\"-------------------------\")\n",
    "    \n",
    "    res = client.models.generate_content(\n",
    "      model=\"gemini-2.5-flash-preview-04-17\",\n",
    "      contents=[\n",
    "          prompt.format(\n",
    "              links_to_inject=links_to_inject,\n",
    "              current_page_markdown_content=current_page.page_content,\n",
    "          )],\n",
    "      config={\n",
    "            'response_mime_type': 'application/json',\n",
    "            'response_schema': MarkdownContentWithUrl,\n",
    "        }\n",
    "      )\n",
    "\n",
    "    print(res.parsed.current_page_markdown_content)\n",
    "    print(\"******************************************\")\n",
    "    print(\"******************************************\")\n",
    "    print(\"******************************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4bde7-60e5-41ca-994a-3429682d303e",
   "metadata": {},
   "source": [
    "# Calculate Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de0169-ae46-4fd3-9aaf-48e1732e0fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# NORMALISED PRICE TABLE\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# • Top-level key  = model name\n",
    "# • Second level   = *billing group* (input / output / cached / cached_hourly)\n",
    "# • Third level    = one of\n",
    "#     • {\"flat\":  rate}                         → same rate for all tokens\n",
    "#     • {\"tiers\": {low: rate, high: rate}, \"threshold\": N}   → tiered pricing\n",
    "#     • {\"by_key\": {sub_key: rate, …}}         → keyed pricing (modalities,  \n",
    "#       thinking/non-thinking, etc.)\n",
    "\n",
    "pricing: dict[str, dict] = {\n",
    "    \"gemini-2.5-pro-exp-03-25\": {\n",
    "        \"input\":   {\"tiers\": {\"low\": 1.25e-6,  \"high\": 2.50e-6},  \"threshold\": 200_000},\n",
    "        \"output\":  {\"tiers\": {\"low\": 10.00e-6, \"high\": 15.00e-6}, \"threshold\": 200_000},\n",
    "        \"cached\":  {\"tiers\": {\"low\": 0.31e-6,  \"high\": 0.625e-6}, \"threshold\": 200_000},\n",
    "        \"cached_hourly\": {\"flat\": 4.50e-6},          # separate if you bill by hour\n",
    "    },\n",
    "\n",
    "    \"gemini-2.5-flash-preview-04-17\": {\n",
    "        \"input\":   {\"flat\": 0.15e-6},                      # same for every token\n",
    "        \"output\":  {\"by_key\": {                           # keyed by token *type*\n",
    "            \"non_thinking\": 0.60e-6,                      # (= candidates)\n",
    "            \"thinking\":     3.50e-6,                      # (= thoughts)\n",
    "        }},\n",
    "        \"cached\":  {\"by_key\": {\"context\": 0.0, \"storage\": 0.0}},\n",
    "    },\n",
    "}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# TOKEN EXTRACTION  (UNCHANGED – SHOWN HERE FOR COMPLETENESS)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def get_tokens(response) -> Dict:\n",
    "    tokens = {\n",
    "        \"input\": {\n",
    "            \"prompt\": response.usage_metadata.prompt_token_count,\n",
    "            \"prompt_details\": {p.modality.value:p.token_count for p in response.usage_metadata.prompt_tokens_details},\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"candidates\": response.usage_metadata.candidates_token_count,\n",
    "            \"thoughts\": response.usage_metadata.thoughts_token_count,\n",
    "        },\n",
    "        \"cached\": response.usage_metadata.cached_content_token_count or 0,\n",
    "        \"total\": response.usage_metadata.total_token_count,\n",
    "    }\n",
    "    return tokens\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# GENERIC PRICE CALCULATOR\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def _tier(prompt_tokens: int, cfg: dict) -> str:\n",
    "    \"\"\"Return 'low' or 'high' if tiered, else ''.\"\"\"\n",
    "    return (\n",
    "        \"low\"\n",
    "        if prompt_tokens <= cfg[\"threshold\"]\n",
    "        else \"high\"\n",
    "    )\n",
    "\n",
    "def _cost_for_group(\n",
    "    token_count: int | dict[str, int],\n",
    "    cfg: dict,\n",
    "    prompt_tokens: int | None = None,\n",
    ") -> float:\n",
    "    # ─── 1. Flat rate ────────────────────────────────────────────────────────\n",
    "    if \"flat\" in cfg:\n",
    "        rate = cfg[\"flat\"]\n",
    "        return token_count * rate if isinstance(token_count, int) else sum(\n",
    "            c * rate for c in token_count.values()\n",
    "        )\n",
    "\n",
    "    # ─── 2. Tiered rate ──────────────────────────────────────────────────────\n",
    "    if \"tiers\" in cfg:\n",
    "        tier  = \"low\" if prompt_tokens <= cfg[\"threshold\"] else \"high\"\n",
    "        rate  = cfg[\"tiers\"][tier]\n",
    "        return token_count * rate if isinstance(token_count, int) else sum(\n",
    "            c * rate for c in token_count.values()\n",
    "        )\n",
    "\n",
    "    # ─── 3. Keyed rate (by_key) ──────────────────────────────────────────────\n",
    "    if \"by_key\" in cfg:\n",
    "        rates = cfg[\"by_key\"]\n",
    "\n",
    "        # 3a. Token count is single int → all tokens billed with *one* rate\n",
    "        if isinstance(token_count, int):\n",
    "            unique_rates = set(rates.values())\n",
    "            if len(unique_rates) != 1:\n",
    "                raise ValueError(\n",
    "                    \"Token total given, but different rates per key: \"\n",
    "                    f\"{rates}. Pass a breakdown or merge the rates.\"\n",
    "                )\n",
    "            rate = unique_rates.pop()     # they’re all the same\n",
    "            return token_count * rate\n",
    "\n",
    "        # 3b. Token count is already per-key dict\n",
    "        return sum(token_count.get(k, 0) * r for k, r in rates.items())\n",
    "\n",
    "    raise ValueError(f\"Unsupported pricing config: {cfg!r}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def compute_price(\n",
    "    model_name: str,\n",
    "    tokens: Dict,\n",
    "    price_table: dict[str, dict] = pricing,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Generic price calculator that supports flat, tiered, and keyed pricing.\n",
    "    \"\"\"\n",
    "    cfg = price_table[model_name]\n",
    "    prompt_tokens = tokens[\"input\"][\"prompt\"]\n",
    "\n",
    "    # INPUT ──────────────────────────────────────────────────────────────────\n",
    "    input_tokens = (\n",
    "        tokens[\"input\"][\"prompt_details\"]          # per-modality\n",
    "        if \"by_key\" in cfg[\"input\"]\n",
    "        else prompt_tokens                         # single number\n",
    "    )\n",
    "    input_cost = _cost_for_group(input_tokens, cfg[\"input\"], prompt_tokens)\n",
    "\n",
    "    # OUTPUT ─────────────────────────────────────────────────────────────────\n",
    "    if \"by_key\" in cfg[\"output\"]:                 # thinking / non-thinking\n",
    "        output_tokens = {\n",
    "            \"non_thinking\": tokens[\"output\"][\"candidates\"],\n",
    "            \"thinking\":     tokens[\"output\"][\"thoughts\"],\n",
    "        }\n",
    "    else:                                         # tiered or flat\n",
    "        output_tokens = (\n",
    "            tokens[\"output\"][\"candidates\"]\n",
    "            + tokens[\"output\"][\"thoughts\"]\n",
    "        )\n",
    "    output_cost = _cost_for_group(output_tokens, cfg[\"output\"], prompt_tokens)\n",
    "\n",
    "    # CACHED ────────────────────────────────────────────────────────────────\n",
    "    cached_tokens = tokens[\"cached\"]\n",
    "    cached_cost = _cost_for_group(cached_tokens, cfg[\"cached\"], prompt_tokens)\n",
    "\n",
    "    # TOTAL ─────────────────────────────────────────────────────────────────\n",
    "    total_cost = input_cost + output_cost + cached_cost\n",
    "    return {\n",
    "        \"input_cost_usd\":  round(input_cost,  6),\n",
    "        \"output_cost_usd\": round(output_cost, 6),\n",
    "        \"cached_cost_usd\": round(cached_cost, 6),\n",
    "        \"total_cost_usd\":  round(total_cost, 6),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb67d4-5903-4d0c-ba0d-d5c1de1c5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_parsing = get_tokens(response)\n",
    "price_parsing  = compute_price(\"gemini-2.5-pro-exp-03-25\", tokens_parsing)\n",
    "print(price_parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d70475-bf89-457b-b782-903c64c6ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_pp = get_tokens(res)\n",
    "price_pp  = compute_price(\"gemini-2.5-flash-preview-04-17\", tokens_pp)\n",
    "print(price_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d22cc-c510-4619-a738-ca5b7cc3d56b",
   "metadata": {},
   "source": [
    "# Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c15f94-51a6-4b0f-80ad-e4d15b6052ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77dd2b47-db01-4cd8-84cf-e651416aad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_obj = {\n",
    "    \"raw_content\": [pc.model_dump() for pc in response.parsed.content],\n",
    "    \"summary\": response.parsed.summary,\n",
    "    \"structured_content\": [sc.model_dump() for sc in response.parsed.structured_content],\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(os.path.join(OUTPUT_PATH, fn.replace(\".pdf\", \".json\")), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dict_obj, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f790a591-6321-43b8-be14-c89e1e3500f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_PATH = os.path.join(OUTPUT_PATH, fn.replace(\".pdf\", \"_metadata.json\"))\n",
    "\n",
    "metadata = {\n",
    "    \"n_pages\": n_pages,\n",
    "    \"parsing\": {\n",
    "        \"tokens\": tokens_parsing,\n",
    "        \"price\": price_parsing,\n",
    "    },\n",
    "    \"post_processing\": {\n",
    "        \"tokens\": tokens_pp,\n",
    "        \"price\": price_pp,\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(METADATA_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27262c1c-62e1-4574-bbc6-578a4d392a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_data_prep",
   "language": "python",
   "name": "venv_data_prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
